# Fluentd configuration file
# Monitor all application logs in /apps/logs/*/app.log
<source>
  @type tail
  path /apps/logs/*/app.log
  pos_file /var/log/td-agent/logs.pos
  tag app.*
  path_key filepath
  <parse>
    @type none
  </parse>
</source>

# Extract project name from the file path
<filter app.**>
  @type record_transformer
  enable_ruby true
  <record>
    project_name ${filepath.split('/')[3]}
    server_name ${ENV['SERVER_NAME'] || 'default-server'}
  </record>
</filter>

# Parse logs - adjust this based on your log format
<filter app.**>
  @type parser
  key_name message
  reserve_data true
  <parse>
    @type json
    # If logs are not JSON, use:
    # @type regexp
    # expression /your regex pattern here/
    # Or for plain text:
    # @type none
  </parse>
</filter>

# Output to Elasticsearch
<match app.**>
  @type elasticsearch
  host ${ELASTICSEARCH_HOST}
  port ${ELASTICSEARCH_PORT}
  user ${ELASTICSEARCH_USER}
  password ${ELASTICSEARCH_PASSWORD}
  scheme ${ELASTICSEARCH_SCHEME}
  ssl_verify ${ELASTICSEARCH_SSL_VERIFY}
  
  # Dynamic index name: server_name-project_name-date
  index_name ${server_name}-${project_name}-%Y.%m.%d
  
  # Buffer configuration
  <buffer time,project_name>
    @type memory
    timekey 1d
    timekey_wait 10m
    flush_mode immediate
    flush_interval 5s
  </buffer>
  
  # Elasticsearch settings
  include_timestamp true
  type_name _doc
  reconnect_on_error true
  reload_on_failure true
  reload_connections true
  request_timeout 30s
  
  # Connection pool
  resurrect_after 5s
  retry_forever false
  retry_max_times 5
  retry_wait 1s
  retry_exponential_backoff_base 2
  retry_max_interval 60s
</match>

# Optional: Monitor Fluentd itself
<source>
  @type monitor_agent
  bind 0.0.0.0
  port 24220
</source>

# Optional: Debug output
<match fluent.**>
  @type stdout
</match>